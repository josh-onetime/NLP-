{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from pandas_datareader import data as web\n",
    "import datetime\n",
    "from statistics import mean,median,mode,stdev\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: Sentiment Analysis on Movie Reviews\n",
    "\n",
    "Objective: The goal of this project is to build a sentiment analysis model that can classify movie reviews as either positive or negative.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "<b>Data Collection</b>: Use the IMDB movie reviews dataset. This dataset contains 50,000 movie reviews that are labeled as either positive or negative. You can download the dataset from this link.\n",
    "\n",
    "<b>Data Cleaning</b>: Clean the text data by removing unnecessary characters, converting all text to lowercase, and removing stop words.\n",
    "\n",
    "<b>Data Exploration</b>: Explore the dataset to understand the distribution of positive and negative reviews. You can also explore the most common words in positive and negative reviews.\n",
    "\n",
    "<b>Feature Extraction</b>: Use techniques like Bag of Words, TF-IDF, or word embeddings to convert the text data into numerical features that can be used by a machine learning model.\n",
    "\n",
    "<b>Model Building</b>: Build a machine learning model to classify the reviews. You can start with a simple model like Logistic Regression, and then try more complex models like SVM or Random Forest. You can also experiment with deep learning models like LSTM or GRU.\n",
    "\n",
    "<b>Model Evaluation</b>: Evaluate the performance of your model using appropriate metrics like accuracy, precision, recall, and F1 score. Also, create a confusion matrix to understand the performance of your model in more detail.\n",
    "\n",
    "<b>Hyperparameter Tuning</b>: Tune the hyperparameters of your model to improve its performance.\n",
    "\n",
    "<b>Model Interpretation</b>: Try to understand why your model is making certain predictions. You can use techniques like SHAP or LIME for model interpretation.\n",
    "\n",
    "<i>Tools: Python, Pandas, Scikit-learn, NLTK, Keras</i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords from nltk, do so\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Convert to lowercase\n",
    "df['review_cleaned'] = df['review'].str.lower()\n",
    "\n",
    "# Remove punctuation and any other non-alphabet characters\n",
    "df['review_cleaned'] = df['review_cleaned'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "\n",
    "# Remove stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df['review_cleaned'] = df['review_cleaned'].apply(lambda x: ' '.join(word for word in x.split() if word not in stopwords))\n",
    "df = df.drop('review', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive average word count is 122.84004\n",
      "negative average word count is 120.27868\n"
     ]
    }
   ],
   "source": [
    "# average word counts of various reviews\n",
    "df['word_count'] = df['review_cleaned'].apply(lambda x: len(str(x).split()))\n",
    "positive_ave = df[df['sentiment'] == 'positive']['word_count'].mean()\n",
    "negative_ave = df[df['sentiment'] == 'negative']['word_count'].mean()\n",
    "\n",
    "print(\"positive average word count is\", positive_ave)\n",
    "print(\"negative average word count is\", negative_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       121.559360\n",
       "std         91.591626\n",
       "min          3.000000\n",
       "25%         65.000000\n",
       "50%         90.000000\n",
       "75%        148.000000\n",
       "max       1440.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [(oz, 5), (violence, 4), (br, 3), (show, 3), (...\n",
      "1        [(br, 6), (well, 3), (little, 2), (production,...\n",
      "2        [(thought, 2), (comedy, 2), (may, 2), (br, 2),...\n",
      "3        [(jake, 4), (parents, 3), (br, 3), (movie, 3),...\n",
      "4        [(one, 6), (br, 5), (mr, 3), (people, 3), (dif...\n",
      "                               ...                        \n",
      "49995    [(movie, 4), (like, 2), (always, 2), (classic,...\n",
      "49996    [(bad, 4), (br, 2), (better, 2), (watch, 2), (...\n",
      "49997    [(catholic, 3), (tragedy, 3), (taught, 2), (ce...\n",
      "49998    [(one, 4), (like, 2), (im, 1), (going, 1), (di...\n",
      "49999    [(movie, 7), (movies, 3), (far, 2), (even, 2),...\n",
      "Name: most_common_words, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "df['most_common_words'] = df['review_cleaned'].apply(lambda x: Counter(str(x).split()).most_common())\n",
    "\n",
    "print(df['most_common_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(df):\n",
    "    common_words = []\n",
    "    for i in range(len(df)):\n",
    "        common_words.append(df['most_common_words'].iloc[i][0])\n",
    "\n",
    "\n",
    "    max_values = {}\n",
    "    for item in common_words:\n",
    "        first_value = item[0]\n",
    "        second_value = item[1]\n",
    "        if first_value in max_values:\n",
    "            if second_value > max_values[first_value][1]:\n",
    "                max_values[first_value] = item\n",
    "        else:\n",
    "            max_values[first_value] = item\n",
    "\n",
    "    common_words = list(max_values.values())\n",
    "\n",
    "    #sort values\n",
    "    common_words = sorted(common_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(br, 59)</td>\n",
       "      <td>(br, 80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(marty, 36)</td>\n",
       "      <td>(like, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(tony, 35)</td>\n",
       "      <td>(victor, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(rob, 34)</td>\n",
       "      <td>(movie, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(custer, 33)</td>\n",
       "      <td>(film, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(titanic, 33)</td>\n",
       "      <td>(zombie, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(match, 30)</td>\n",
       "      <td>(jesse, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(scarlett, 30)</td>\n",
       "      <td>(trivialboring, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(sam, 29)</td>\n",
       "      <td>(puppet, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ring, 27)</td>\n",
       "      <td>(timon, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(prot, 27)</td>\n",
       "      <td>(macbeth, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(sheba, 27)</td>\n",
       "      <td>(bridget, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(film, 25)</td>\n",
       "      <td>(critters, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(bond, 25)</td>\n",
       "      <td>(jokes, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(guy, 25)</td>\n",
       "      <td>(superman, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(world, 24)</td>\n",
       "      <td>(joe, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(greatest, 24)</td>\n",
       "      <td>(blob, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(heart, 24)</td>\n",
       "      <td>(tibbs, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(movie, 23)</td>\n",
       "      <td>(gray, 21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(holmes, 23)</td>\n",
       "      <td>(mary, 21)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          positive             negative\n",
       "0         (br, 59)             (br, 80)\n",
       "1      (marty, 36)           (like, 31)\n",
       "2       (tony, 35)         (victor, 31)\n",
       "3        (rob, 34)          (movie, 28)\n",
       "4     (custer, 33)           (film, 27)\n",
       "5    (titanic, 33)         (zombie, 27)\n",
       "6      (match, 30)          (jesse, 27)\n",
       "7   (scarlett, 30)  (trivialboring, 26)\n",
       "8        (sam, 29)         (puppet, 25)\n",
       "9       (ring, 27)          (timon, 25)\n",
       "10      (prot, 27)        (macbeth, 24)\n",
       "11     (sheba, 27)        (bridget, 24)\n",
       "12      (film, 25)       (critters, 23)\n",
       "13      (bond, 25)          (jokes, 23)\n",
       "14       (guy, 25)       (superman, 22)\n",
       "15     (world, 24)            (joe, 22)\n",
       "16  (greatest, 24)           (blob, 22)\n",
       "17     (heart, 24)          (tibbs, 22)\n",
       "18     (movie, 23)           (gray, 21)\n",
       "19    (holmes, 23)           (mary, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg = df[df['sentiment'] == 'negative']\n",
    "df_pos = df[df['sentiment'] == 'positive']   \n",
    "\n",
    "df_common_words = pd.DataFrame()\n",
    "df_common_words['positive'] = common_words(df_pos)\n",
    "df_common_words['negative'] = pd.Series(common_words(df_neg))\n",
    "\n",
    "\n",
    "df_common_words.head(20)\n",
    "\n",
    "# not really the most useful ngl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X1 = vectorizer.fit_transform(df['review_cleaned'])\n",
    "\n",
    "# Now, X is a matrix where each row corresponds to a document and each column is a word from the vocabulary.\n",
    "# The entries of this matrix are the frequencies of each word in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X2 = vectorizer.fit_transform(df['review_cleaned'])\n",
    "\n",
    "# Now, X is a matrix where each row corresponds to a document and each column is a word from the vocabulary.\n",
    "# The entries of this matrix are the TF-IDF scores of each word in each document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of TFIDF:\n",
    "\n",
    "Term Frequency-Inverse Document Frequency. It's a numerical statistic that reflects how important a word is to a document in a collection or corpus.\n",
    "\n",
    "Term Frequency (TF): This summarizes how often a given word appears within a document.\n",
    "\n",
    "Inverse Document Frequency (IDF): This downscales words that appear a lot across documents. A word is not of much use to us if it’s appearing in all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = gensim.models.Word2Vec(df['review_cleaned'], min_count=1)\n",
    "\n",
    "# Now, model is a Word2Vec model that can be used to create word embeddings.\n",
    "# You can get the embedding of a word by calling model[word].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Model Building: Build a machine learning model to classify the reviews. You can start with a simple model like Logistic Regression, and then try more complex models like SVM or Random Forest. You can also experiment with deep learning models like LSTM or GRU.\n",
    "\n",
    "Model Evaluation: Evaluate the performance of your model using appropriate metrics like accuracy, precision, recall, and F1 score. Also, create a confusion matrix to understand the performance of your model in more detail.\n",
    "\n",
    "Hyperparameter Tuning: Tune the hyperparameters of your model to improve its performance.\n",
    "\n",
    "Model Interpretation: Try to understand why your model is making certain predictions. You can use techniques like SHAP or LIME for model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['labels','reviews','word_count','common_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming df is your DataFrame, 'reviews' is the column with the reviews, and 'labels' is the column with the labels\n",
    "X = df['reviews']\n",
    "y = df['labels']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a pipeline that first transforms the text data into TF-IDF features, then trains a logistic regression model\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89      5044\n",
      "    positive       0.88      0.91      0.89      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X_test.iloc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a terrible movie lmao</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is a great amazing awesome movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>some good parts but overall terrible</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this movie is somewhat decent, but not that gr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely incredible</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>absolute trash</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews predictions\n",
       "0                      this is a terrible movie lmao    negative\n",
       "1              this is a great amazing awesome movie    positive\n",
       "2               some good parts but overall terrible    negative\n",
       "3  this movie is somewhat decent, but not that gr...    positive\n",
       "4                              absolutely incredible    positive\n",
       "5                                     absolute trash    negative"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_own = pd.DataFrame()\n",
    "df_own['reviews'] = ['this is a terrible movie lmao','this is a great amazing awesome movie','some good parts but overall terrible','this movie is somewhat decent, but not that great too','absolutely incredible','absolute trash']\n",
    "df_own['predictions'] = pipeline.predict(df_own['reviews'])\n",
    "df_own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: 0.093*\"learning\" + 0.040*\"machine\" + 0.040*\"neural\" + 0.040*\"subfield\" + 0.040*\"focuses\" + 0.040*\"Deep\" + 0.040*\"networks.\" + 0.040*\"exciting\" + 0.040*\"field\" + 0.040*\"applications.\"\n",
      "Topic #2: 0.077*\"language\" + 0.046*\"machine\" + 0.046*\"Natural\" + 0.046*\"helps\" + 0.046*\"processing\" + 0.046*\"language.\" + 0.046*\"generating\" + 0.046*\"human\" + 0.046*\"understanding\" + 0.046*\"programming\"\n"
     ]
    }
   ],
   "source": [
    "# topic modelling\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Machine learning is an exciting field with numerous applications.\",\n",
    "    \"Natural language processing helps in understanding and generating human language.\",\n",
    "    \"Deep learning is a subfield of machine learning that focuses on neural networks.\",\n",
    "    \"Topic modeling can discover hidden topics in a collection of documents.\",\n",
    "    \"Python is a popular programming language for data analysis and machine learning.\"\n",
    "]\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_docs = [doc.split() for doc in documents]\n",
    "\n",
    "# Remove stopwords; using a function because we're overkill\n",
    "def remove_elements(list_of_lists, removal_list):\n",
    "    return [[item for item in sublist if item not in removal_list] for sublist in list_of_lists]\n",
    "\n",
    "td = remove_elements(tokenized_docs,stopwords)\n",
    "\n",
    "# Create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(td)\n",
    "\n",
    "# Create a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=2, id2word=dictionary, passes=10)\n",
    "\n",
    "# Print the topics\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic #{idx+1}: {topic}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
